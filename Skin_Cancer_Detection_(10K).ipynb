{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JkLd3-AXV4yN",
        "outputId": "fac0cf60-fe3c-4c41-cf4f-08367e45ff8b"
      },
      "outputs": [],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "75R1Jn2-WNEu",
        "outputId": "9d0b19d7-791c-4f09-c551-68890053e0d5"
      },
      "outputs": [],
      "source": [
        "!pip install ultralytics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LP--O9VhWRcW",
        "outputId": "1872284d-831c-42f2-9d0d-303f0e867d74"
      },
      "outputs": [],
      "source": [
        "import ultralytics\n",
        "ultralytics.checks()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dG2-07cyWUhP"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import seaborn as sns\n",
        "import cv2\n",
        "import os\n",
        "\n",
        "print(f\"TensorFlow version: {tf.__version__}\")\n",
        "print(f\"GPU available: {tf.config.list_physical_devices('GPU')}\")\n",
        "print(f\"Keras version: {keras.__version__}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "EvthEHUkWXI3",
        "outputId": "21c8b0b9-44c4-4443-f398-9857bbeac5bf"
      },
      "outputs": [],
      "source": [
        "!pip install kaggle\n",
        "\n",
        "import os\n",
        "import kaggle\n",
        "from kaggle.api.kaggle_api_extended import KaggleApi\n",
        "\n",
        "# Initialize Kaggle API\n",
        "api = KaggleApi()\n",
        "api.authenticate()\n",
        "\n",
        "# Download skin cancer dataset from Kaggle\n",
        "# You can replace this with any skin cancer dataset from Kaggle\n",
        "dataset_name = \"fanconic/skin-cancer-malignant-vs-benign\"  # Example dataset\n",
        "download_path = \"./skin_cancer_dataset\"\n",
        "\n",
        "# Create directory if it doesn't exist\n",
        "os.makedirs(download_path, exist_ok=True)\n",
        "\n",
        "# Download the dataset\n",
        "api.dataset_download_files(dataset_name, path=download_path, unzip=True)\n",
        "\n",
        "print(f\"Dataset downloaded to: {download_path}\")\n",
        "print(\"Available files:\")\n",
        "for root, dirs, files in os.walk(download_path):\n",
        "    for file in files[:10]:  # Show first 10 files\n",
        "        print(f\"  {os.path.join(root, file)}\")\n",
        "    if len(files) > 10:\n",
        "        print(f\"  ... and {len(files) - 10} more files\")\n",
        "    break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "Tx7Jo6i8Wy6K",
        "outputId": "774f8b34-071d-4f1d-a100-299db0c0a822"
      },
      "outputs": [],
      "source": [
        "# Check the downloaded dataset structure\n",
        "data_dir = \"./skin_cancer_dataset\"\n",
        "\n",
        "print(f\"Dataset location: {data_dir}\")\n",
        "print(\"\\nDataset structure:\")\n",
        "for root, dirs, files in os.walk(data_dir):\n",
        "    level = root.replace(data_dir, '').count(os.sep)\n",
        "    indent = ' ' * 2 * level\n",
        "    print(f\"{indent}{os.path.basename(root)}/\")\n",
        "    sub_indent = ' ' * 2 * (level + 1)\n",
        "    for file in files[:5]:  # Show first 5 files in each directory\n",
        "        print(f\"{sub_indent}{file}\")\n",
        "    if len(files) > 5:\n",
        "        print(f\"{sub_indent}... and {len(files) - 5} more files\")\n",
        "        \n",
        "print(f\"\\nTotal number of directories: {len(dirs) if 'dirs' in locals() else 'N/A'}\")\n",
        "print(f\"Ready for CNN training!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a8Eb6cWrWz_i",
        "outputId": "101d8f0f-ac94-423a-fa4f-202dccfaa0b3"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "import cv2\n",
        "\n",
        "# Set up data directories\n",
        "data_dir = \"./skin_cancer_dataset\"\n",
        "img_height, img_width = 224, 224\n",
        "batch_size = 32\n",
        "\n",
        "# Create data generators\n",
        "datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    validation_split=0.2,\n",
        "    rotation_range=20,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    zoom_range=0.2\n",
        ")\n",
        "\n",
        "# Load training data\n",
        "train_generator = datagen.flow_from_directory(\n",
        "    data_dir,\n",
        "    target_size=(img_height, img_width),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical',\n",
        "    subset='training'\n",
        ")\n",
        "\n",
        "# Load validation data\n",
        "validation_generator = datagen.flow_from_directory(\n",
        "    data_dir,\n",
        "    target_size=(img_height, img_width),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical',\n",
        "    subset='validation'\n",
        ")\n",
        "\n",
        "# Build CNN model\n",
        "model = keras.Sequential([\n",
        "    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(img_height, img_width, 3)),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "    layers.Conv2D(128, (3, 3), activation='relu'),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "    layers.Conv2D(128, (3, 3), activation='relu'),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "    layers.Flatten(),\n",
        "    layers.Dropout(0.5),\n",
        "    layers.Dense(512, activation='relu'),\n",
        "    layers.Dense(train_generator.num_classes, activation='softmax')\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(\n",
        "    optimizer='adam',\n",
        "    loss='categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "# Display model architecture\n",
        "model.summary()\n",
        "\n",
        "# Train the model\n",
        "epochs = 100\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    steps_per_epoch=train_generator.samples // batch_size,\n",
        "    epochs=epochs,\n",
        "    validation_data=validation_generator,\n",
        "    validation_steps=validation_generator.samples // batch_size,\n",
        "    verbose=1\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Plot training history\n",
        "plt.figure(figsize=(12, 4))\n",
        "\n",
        "# Plot training & validation accuracy\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('Model Accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Training', 'Validation'], loc='upper left')\n",
        "\n",
        "# Plot training & validation loss\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('Model Loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Training', 'Validation'], loc='upper left')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Print final training results\n",
        "final_train_acc = history.history['accuracy'][-1]\n",
        "final_val_acc = history.history['val_accuracy'][-1]\n",
        "final_train_loss = history.history['loss'][-1]\n",
        "final_val_loss = history.history['val_loss'][-1]\n",
        "\n",
        "print(f\"\\nFinal Training Accuracy: {final_train_acc:.4f}\")\n",
        "print(f\"Final Validation Accuracy: {final_val_acc:.4f}\")\n",
        "print(f\"Final Training Loss: {final_train_loss:.4f}\")\n",
        "print(f\"Final Validation Loss: {final_val_loss:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Evaluate the model on validation data\n",
        "val_loss, val_accuracy = model.evaluate(validation_generator, verbose=0)\n",
        "print(f\"Validation Accuracy: {val_accuracy:.4f}\")\n",
        "print(f\"Validation Loss: {val_loss:.4f}\")\n",
        "\n",
        "# Generate predictions for confusion matrix\n",
        "validation_generator.reset()\n",
        "predictions = model.predict(validation_generator, verbose=1)\n",
        "predicted_classes = np.argmax(predictions, axis=1)\n",
        "\n",
        "# Get true labels\n",
        "true_classes = validation_generator.classes\n",
        "class_labels = list(validation_generator.class_indices.keys())\n",
        "\n",
        "# Create confusion matrix\n",
        "cm = confusion_matrix(true_classes, predicted_classes)\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
        "            xticklabels=class_labels, yticklabels=class_labels)\n",
        "plt.title('Confusion Matrix')\n",
        "plt.ylabel('True Label')\n",
        "plt.xlabel('Predicted Label')\n",
        "plt.show()\n",
        "\n",
        "# Print classification report\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(true_classes, predicted_classes, target_names=class_labels))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Save the trained model\n",
        "model.save('skin_cancer_cnn_model.h5')\n",
        "print(\"Model saved as 'skin_cancer_cnn_model.h5'\")\n",
        "\n",
        "# Function to predict on a single image\n",
        "def predict_image(image_path, model, class_labels):\n",
        "    \"\"\"\n",
        "    Predict the class of a single image\n",
        "    \"\"\"\n",
        "    # Load and preprocess the image\n",
        "    img = tf.keras.preprocessing.image.load_img(image_path, target_size=(224, 224))\n",
        "    img_array = tf.keras.preprocessing.image.img_to_array(img)\n",
        "    img_array = tf.expand_dims(img_array, 0)  # Create batch dimension\n",
        "    img_array /= 255.0  # Normalize\n",
        "    \n",
        "    # Make prediction\n",
        "    predictions = model.predict(img_array, verbose=0)\n",
        "    predicted_class_idx = np.argmax(predictions[0])\n",
        "    confidence = predictions[0][predicted_class_idx]\n",
        "    predicted_class = class_labels[predicted_class_idx]\n",
        "    \n",
        "    return predicted_class, confidence, predictions[0]\n",
        "\n",
        "# Function to display prediction results\n",
        "def display_prediction(image_path, model, class_labels):\n",
        "    \"\"\"\n",
        "    Display image with prediction results\n",
        "    \"\"\"\n",
        "    predicted_class, confidence, all_predictions = predict_image(image_path, model, class_labels)\n",
        "    \n",
        "    # Display image\n",
        "    img = plt.imread(image_path)\n",
        "    plt.figure(figsize=(10, 4))\n",
        "    \n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.imshow(img)\n",
        "    plt.title(f'Predicted: {predicted_class}\\nConfidence: {confidence:.2%}')\n",
        "    plt.axis('off')\n",
        "    \n",
        "    # Display prediction probabilities\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.bar(class_labels, all_predictions)\n",
        "    plt.title('Prediction Probabilities')\n",
        "    plt.ylabel('Probability')\n",
        "    plt.xticks(rotation=45)\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "    \n",
        "    return predicted_class, confidence\n",
        "\n",
        "print(\"Prediction functions defined. Use predict_image() or display_prediction() to test on new images.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Example: Test prediction on a sample image from the validation set\n",
        "# Get a few sample images from validation data\n",
        "import random\n",
        "\n",
        "# Get some sample images from the dataset\n",
        "sample_images = []\n",
        "for root, dirs, files in os.walk(data_dir):\n",
        "    for file in files:\n",
        "        if file.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
        "            sample_images.append(os.path.join(root, file))\n",
        "            if len(sample_images) >= 5:  # Get 5 sample images\n",
        "                break\n",
        "    if len(sample_images) >= 5:\n",
        "        break\n",
        "\n",
        "if sample_images:\n",
        "    print(f\"Testing prediction on {len(sample_images)} sample images:\")\n",
        "    print(\"Class labels:\", list(train_generator.class_indices.keys()))\n",
        "    \n",
        "    # Test on first sample image\n",
        "    if len(sample_images) > 0:\n",
        "        sample_image = sample_images[0]\n",
        "        print(f\"\\nTesting on: {sample_image}\")\n",
        "        predicted_class, confidence = display_prediction(\n",
        "            sample_image, \n",
        "            model, \n",
        "            list(train_generator.class_indices.keys())\n",
        "        )\n",
        "        print(f\"Prediction: {predicted_class} ({confidence:.2%} confidence)\")\n",
        "else:\n",
        "    print(\"No sample images found. Please ensure the dataset is properly downloaded and extracted.\")\n",
        "    print(\"You can test predictions later using:\")\n",
        "    print(\"display_prediction('path_to_your_image.jpg', model, list(train_generator.class_indices.keys()))\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
